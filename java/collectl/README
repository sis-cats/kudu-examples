This example implements a simple Java application which listens on a
TCP socket for time series data corresponding to the Collectl wire protocol.
The commonly-available 'collectl' tool can be used to send example data
to the server.

This tutorial assumes that you are running a Kudu master on 'quickstart.cloudera'.
Otherwise, you can pass another host using '-DkuduMaster=host:port'.

To start the example server:

$ mvn package
$ java -jar target/kudu-collectl-example-1.0-SNAPSHOT.jar

To start collecting data, run the following command on one or more machines:

$ collectl --export=graphite,127.0.0.1,p=/

(substituting '127.0.0.1' with the IP address of whichever server is running the
example program).

----

Exploring the data with Impala
========

First, we need to map the table into Impala:

    CREATE EXTERNAL TABLE `metrics` (
    `host` STRING,
    `metric` STRING,
    `timestamp` INT,
    `value` DOUBLE
    )
    TBLPROPERTIES(
      'storage_handler' = 'com.cloudera.kudu.hive.KuduStorageHandler',
      'kudu.table_name' = 'metrics',
      'kudu.master_addresses' = 'quickstart.cloudera:7051',
      'kudu.key_columns' = 'host, metric, timestamp'
    );

Then, we can run some queries:

    [quickstart.cloudera:21000] > select count(distinct metric) from metrics;
    Query: select count(distinct metric) from metrics
    +------------------------+
    | count(distinct metric) |
    +------------------------+
    | 23                     |
    +------------------------+
    Fetched 1 row(s) in 0.19s


Exploring the data with Spark
========

NOTE: if you are using the Quickstart VM, Spark is not installed by default.
You can install it by running:

    sudo yum -y install spark-core

Download the Kudu MR jar and run Spark with it on the classpath:

    wget https://repository.cloudera.com/artifactory/cloudera-repos/org/apache/kudu/kudu-spark_2.10/0.10.0/kudu-spark_2.10-0.10.0.jar
    spark-shell --jars kudu-spark*jar

You can then paste this example script:

    import org.apache.kudu.spark.kudu._

    val df = sqlContext.read.options(Map(
      "kudu.master" -> "quickstart.cloudera",
      "kudu.table" -> "metrics")).kudu
    df.registerTempTable("metrics")

    // Print the first five values
    sqlContext.sql("select * from metrics limit 5").show()
    
    // Calculate the average value of every host/metric pair
    sqlContext.sql("select host, metric, avg(value) from metrics group by host, metric").show()
    
Note that if you are still running the 'collectl' command above, you can see
the data changing in real time by re-running the queries.
